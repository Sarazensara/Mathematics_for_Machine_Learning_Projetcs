{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries involved\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 : \n",
    "# If x and y are two vectors in R^n, to compute xy^T x (without any parallelization), \n",
    "# is it faster to multiply x(y^T x) (meaning we compute in the sequence z = y^T x and then xz)\n",
    "# or (xy^T )x (meaning we compute z = xy^T and then zx)?\n",
    "\n",
    "# Set the size of the vector n\n",
    "n = 1000\n",
    "\n",
    "# Generate random vectors x and y in R^n (each of size n)\n",
    "x = np.random.rand(n)\n",
    "y = np.random.rand(n)\n",
    "\n",
    "# Method 1: x(y^T x)\n",
    "# First compute y^T x, which is the dot product of vectors y and x\n",
    "# This operation gives us a scalar value, the inner product of y and x\n",
    "start_time = time.time()\n",
    "z1 = np.dot(y, x)  # y^T x: Dot product of y and x, results in a scalar value\n",
    "# Then multiply x by the scalar result of y^T x\n",
    "# This operation scales each element of vector x by the scalar z1\n",
    "result1 = x * z1   # x(y^T x): Element-wise multiplication of x by scalar z1\n",
    "method1_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 time: 0.001070 seconds\n",
      "Method 2 time: 0.005175 seconds\n"
     ]
    }
   ],
   "source": [
    "# Method 2: (xy^T) x\n",
    "# Compute the outer product of x and y to create an n x n matrix (xy^T)\n",
    "# This operation produces a matrix where each element is the product of x_i and y_j\n",
    "start_time = time.time()\n",
    "xyT = np.outer(x, y)  # xy^T: Outer product of x and y, creates a matrix\n",
    "# Then compute the dot product of this matrix (xy^T) with the vector x\n",
    "# This results in a new vector (of length n), which is the matrix-vector product\n",
    "result2 = np.dot(xyT, x)  # (xy^T) x: Matrix-vector multiplication of xy^T and x\n",
    "method2_time = time.time() - start_time\n",
    "\n",
    "# Print the time taken for each method\n",
    "print(f\"Method 1 time: {method1_time:.6f} seconds\")  # Time taken for x(y^T x)\n",
    "print(f\"Method 2 time: {method2_time:.6f} seconds\")  # Time taken for (xy^T) x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: \n",
    "# If A is an m by n matrix and m > n, to compute A A^T A (without any parallelization),\n",
    "# is it faster to multiply A(A^T A) or (A A^T)A?\n",
    "\n",
    "# Set the dimensions for the matrix A (m > n)\n",
    "m = 1000\n",
    "n = 500\n",
    "\n",
    "# Generate a random m x n matrix A\n",
    "A = np.random.rand(m, n)\n",
    "\n",
    "# Method 1: A(A^T A)\n",
    "# First, compute A^T A, which is the product of the transpose of A (A^T) and A.\n",
    "# This is an n x n matrix, and it can be seen as capturing the pairwise relationships\n",
    "# between the columns of A.\n",
    "start_time = time.time()\n",
    "AT_A = np.dot(A.T, A)  # A^T A: This is an n x n matrix resulting from the dot product of A^T and A.\n",
    "# Then, multiply A by the matrix A^T A. This involves multiplying the m x n matrix A by the n x n matrix A^T A.\n",
    "# This gives an m x n matrix, where each row of A is transformed by the matrix A^T A.\n",
    "result1 = np.dot(A, AT_A)  # A(A^T A): This is an m x n matrix, resulting from matrix multiplication of A and A^T A.\n",
    "method1_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 time (A(A^T A)): 0.006358 seconds\n",
      "Method 2 time ((A A^T)A): 0.019453 seconds\n"
     ]
    }
   ],
   "source": [
    "# Method 2: (A A^T) A\n",
    "# First, compute A A^T, which is the product of A and its transpose A^T.\n",
    "# This results in an m x m matrix, which represents the pairwise relationships between the rows of A.\n",
    "start_time = time.time()\n",
    "A_AT = np.dot(A, A.T)  # A A^T: This is an m x m matrix resulting from the dot product of A and A^T.\n",
    "# Then, multiply the matrix A A^T by the matrix A. This involves multiplying the m x m matrix A A^T by the m x n matrix A.\n",
    "# The result is an m x n matrix, which is the final output.\n",
    "result2 = np.dot(A_AT, A)  # (A A^T) A: This is an m x n matrix resulting from matrix multiplication of A A^T and A.\n",
    "method2_time = time.time() - start_time\n",
    "\n",
    "# Print the time taken for each method\n",
    "print(f\"Method 1 time (A(A^T A)): {method1_time:.6f} seconds\")  # Time taken for A(A^T A)\n",
    "print(f\"Method 2 time ((A A^T)A): {method2_time:.6f} seconds\")  # Time taken for (A A^T) A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for each digit class (mu_j) and overall mean (mu):\n",
      "mu_0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_2: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_5: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_7: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "Overall mean (mu): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "Projection length onto the pca_full subspace: 0.1027587402632586\n",
      "Projection length onto the pca_mu subspace: 0.10926943877319231\n",
      "Distance between subspaces (Orthogonal Procrustes solution): 2.318089104211143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "# Question 3: \n",
    "# We are working with the MNIST dataset and performing PCA to analyze the data. Specifically,\n",
    "# we compare the principal components obtained from the entire dataset (X) with those obtained from the \n",
    "# mean of each digit class (mu_j for each digit 0-9). We are interested in comparing the subspaces spanned \n",
    "# by the first 10 principal components in two cases: using the full dataset and using the means of each digit \n",
    "# class. Finally, we solve the Orthogonal Procrustes Problem to compute the distance between these two subspaces.\n",
    "\n",
    "# The MNIST dataset\n",
    "mnist = fetch_openml('mnist_784')\n",
    "data = mnist['data']\n",
    "labels = mnist['target'].astype(int)\n",
    "\n",
    "# Prepares the data matrices Xj for each digit and the full data matrix X\n",
    "# X is the full dataset, where each column represents a data point (784-dimensional pixel vector)\n",
    "X = data.values  # All digits (each column is a data point)\n",
    "# X_j is a list of subsets, each containing the data points for a specific digit class j\n",
    "X_j = [X[labels == j] for j in range(10)]  # List of data points for each digit class j\n",
    "\n",
    "# Performs the PCA for each X_j and the full dataset X\n",
    "# PCA on the full dataset to reduce dimensionality, keeping the first 10 principal components\n",
    "pca_full = PCA(n_components=10)\n",
    "pca_full.fit(X)\n",
    "\n",
    "# Performs the PCA for each digit class (X_j) individually\n",
    "pca_digits = [PCA(n_components=10).fit(Xj) for Xj in X_j]\n",
    "\n",
    "# Calculates the means of each digit class and the overall mean\n",
    "# mu_j represents the mean of each digit class, calculated over all data points in class j\n",
    "mu_j = [np.mean(Xj, axis=0) for Xj in X_j]  # Means for each class\n",
    "# mu represents the overall mean of the full dataset, computed across all data points\n",
    "mu = np.mean(X, axis=0)  # Mean for the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for each digit class (mu_j) and overall mean (mu):\n",
      "mu_0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_2: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_5: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_7: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "mu_9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "Overall mean (mu): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n"
     ]
    }
   ],
   "source": [
    "# (a) How do mu_j relate to mu?\n",
    "# Printing the first 10 elements of the mean vectors for brevity\n",
    "print(\"Mean for each digit class (mu_j) and overall mean (mu):\")\n",
    "for j in range(10):\n",
    "    print(f\"mu_{j}: {mu_j[j][:10]}...\")  # Shows first 10 elements for brevity\n",
    "print(f\"Overall mean (mu): {mu[:10]}...\")  # Shows first 10 elements for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection length onto the pca_full subspace: 0.08994069956234291\n",
      "Projection length onto the pca_mu subspace: 0.0944585303877144\n"
     ]
    }
   ],
   "source": [
    "# (b) Perform PCA for {mu_j: j = 0, 1, ..., 9} âˆª {mu}\n",
    "# Combine the means of all digit classes and the overall mean into one matrix\n",
    "mu_combined = np.array(mu_j + [mu])  # Stacks all the means including the overall mean\n",
    "# Performs the PCA on the combined mean vectors, reducing to the first 10 components\n",
    "pca_mu = PCA(n_components=10)\n",
    "pca_mu.fit(mu_combined)\n",
    "\n",
    "# Gets the subspace spanned by the first 10 principal directions for both pca_full and pca_mu\n",
    "# The first 10 components from each PCA object represent the 10 most significant directions\n",
    "subspace_full = pca_full.components_[:10]  # Firsts 10 principal components of full dataset\n",
    "subspace_mu = pca_mu.components_[:10]  # Firsts 10 principal components of means\n",
    "\n",
    "# Generates a random unit vector in 784-dimensional space (matching the number of features in MNIST)\n",
    "random_unit_vector = np.random.randn(784)\n",
    "random_unit_vector /= np.linalg.norm(random_unit_vector)  # Normalize the vector to unit length\n",
    "\n",
    "# Projects the random unit vector onto the subspaces\n",
    "# Projects onto pca_full subspace (10-dimensional space)\n",
    "projection_full = np.dot(random_unit_vector, subspace_full.T)\n",
    "projection_length_full = np.linalg.norm(projection_full)\n",
    "\n",
    "# Then, project onto pca_mu subspace (also 10-dimensional space)\n",
    "projection_mu = np.dot(random_unit_vector, subspace_mu.T)\n",
    "projection_length_mu = np.linalg.norm(projection_mu)\n",
    "\n",
    "# Output the projection lengths to compare how much of the random vector lies in each subspace\n",
    "print(f\"Projection length onto the pca_full subspace: {projection_length_full}\")\n",
    "print(f\"Projection length onto the pca_mu subspace: {projection_length_mu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between subspaces (Orthogonal Procrustes solution): 2.318089104211143\n"
     ]
    }
   ],
   "source": [
    "# Step (c): Solve the Orthogonal Procrustes Problem to compute distance between subspaces\n",
    "# The subspaces are of shape (10, 784), and we need to transpose them to shape (784, 10)\n",
    "# The Orthogonal Procrustes problem finds the best orthogonal rotation matrix that aligns the two subspaces\n",
    "U, _ = orthogonal_procrustes(subspace_mu.T, subspace_full.T)\n",
    "\n",
    "# Aligning the subspaces. We transpose subspace_mu and apply the rotation matrix U\n",
    "# The result is an aligned version of subspace_mu\n",
    "aligned_subspace_mu = np.dot(subspace_mu.T, U)  # (784, 10) x (10, 10) => (784, 10)\n",
    "\n",
    "# Compute the Frobenius norm of the difference between the aligned subspaces\n",
    "# This measures how similar the two subspaces are after applying the orthogonal alignment\n",
    "subspace_distance = np.linalg.norm(subspace_full.T - aligned_subspace_mu)\n",
    "print(f\"Distance between subspaces (Orthogonal Procrustes solution): {subspace_distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
